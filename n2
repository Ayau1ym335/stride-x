import numpy as np
from typing import Dict, List, Tuple, Any, Optional
import json
from dataclasses import dataclass
from enum import Enum


class ClinicalCategory(Enum):
    """Enumeration of clinical categories for gait analysis."""
    HEALTHY = "Healthy"
    TRAUMA = "Trauma"
    ASYMMETRY = "Asymmetry"
    NEURO_RISK = "Neuro Risk"
    TECH_NOISE = "Tech Noise"


@dataclass
class MetricDeviation:
    """Represents a deviation in a specific metric."""
    metric_name: str
    patient_value: float
    reference_value: float
    deviation: float
    deviation_percentage: float
    weight: float


class StridexMathEngine:
    """
    Deterministic mathematical core for Stridex gait analysis.
    
    This engine performs weighted vector similarity comparison between patient
    gait data and a verified clinical reference database. It is designed to be
    completely deterministic to avoid AI hallucinations and ensure medical-grade
    accuracy.
    
    Attributes:
        reference_database (List[Dict]): Verified clinical reference patterns
        metric_weights (Dict[str, float]): Importance weights for each metric
    """
    
    def __init__(self, reference_database: Optional[List[Dict]] = None):
        """
        Initialize the Stridex Mathematical Engine.
        
        Args:
            reference_database: List of clinical reference patterns. If None,
                              uses built-in simulated database.
        """
        self.reference_database = reference_database or self._load_simulated_database()
        self.metric_weights = self._initialize_metric_weights()
        
    def _initialize_metric_weights(self) -> Dict[str, float]:
        """
        Initialize importance weights for each metric.
        
        Higher weights indicate metrics that are more clinically significant
        for pattern matching and diagnosis.
        
        Returns:
            Dictionary mapping metric paths to their weights (0.0 - 1.0)
        """
        return {
            # Variability metrics (highest weight for fall risk detection)
            "session_metrics.variability.gvi": 1.0,
            "session_metrics.variability.step_time_variability": 0.9,
            "session_metrics.variability.knee_angle_variability": 0.85,
            
            # Joint mechanics (critical for trauma detection)
            "session_metrics.joint_mechanics.knee_angle.mean": 0.95,
            "session_metrics.joint_mechanics.knee_angle.amplitude": 0.9,
            "session_metrics.joint_mechanics.knee_angle.max": 0.85,
            "session_metrics.joint_mechanics.knee_angle.min": 0.85,
            "session_metrics.joint_mechanics.knee_angle.std": 0.8,
            
            # Orientation (important for asymmetry)
            "session_metrics.joint_mechanics.orientation.avg_roll": 0.75,
            "session_metrics.joint_mechanics.orientation.avg_pitch": 0.75,
            "session_metrics.joint_mechanics.orientation.avg_yaw": 0.7,
            
            # Rhythm and pace
            "session_metrics.rhythm_pace.cadence": 0.8,
            "session_metrics.rhythm_pace.avg_speed": 0.85,
            "session_metrics.rhythm_pace.avg_peak_angular_velocity": 0.95,
            
            # Symmetry and phases
            "session_metrics.symmetry_phases.stance_swing_ratio": 0.9,
            "session_metrics.symmetry_phases.avg_stance_time": 0.8,
            "session_metrics.symmetry_phases.avg_swing_time": 0.8,
            "session_metrics.symmetry_phases.avg_impact_force": 0.85,
            
            # User profile (lower weight, context only)
            "user_profile.age": 0.3,
            "user_profile.weight": 0.3,
            "user_profile.height": 0.3,
        }
    
    def _extract_nested_value(self, data: Dict, path: str) -> Optional[float]:
        """
        Extract a value from nested dictionary using dot notation path.
        
        Args:
            data: Dictionary to extract from
            path: Dot-separated path (e.g., "session_metrics.variability.gvi")
            
        Returns:
            Extracted value or None if path doesn't exist
        """
        keys = path.split('.')
        value = data
        
        try:
            for key in keys:
                value = value[key]
            return float(value) if value is not None else None
        except (KeyError, TypeError, ValueError):
            return None
    
    def _calculate_weighted_euclidean_distance(
        self, 
        patient_data: Dict, 
        reference_data: Dict
    ) -> Tuple[float, List[MetricDeviation]]:
        """
        Calculate weighted Euclidean distance between patient and reference.
        
        This is the core mathematical algorithm. It computes a distance metric
        that accounts for the clinical importance of each parameter.
        
        Args:
            patient_data: Patient gait metrics
            reference_data: Reference pattern metrics
            
        Returns:
            Tuple of (total_distance, list of deviations)
        """
        squared_weighted_distances = []
        deviations = []
        total_weight = 0.0
        
        for metric_path, weight in self.metric_weights.items():
            patient_value = self._extract_nested_value(patient_data, metric_path)
            reference_value = self._extract_nested_value(reference_data, metric_path)
            
            # Skip if either value is missing
            if patient_value is None or reference_value is None:
                continue
            
            # Calculate deviation
            deviation = patient_value - reference_value
            
            # Handle division by zero for percentage calculation
            if reference_value != 0:
                deviation_pct = (deviation / abs(reference_value)) * 100
            else:
                deviation_pct = 0.0 if deviation == 0 else float('inf')
            
            # Store deviation information
            deviations.append(MetricDeviation(
                metric_name=metric_path,
                patient_value=patient_value,
                reference_value=reference_value,
                deviation=deviation,
                deviation_percentage=deviation_pct,
                weight=weight
            ))
            
            # Weighted squared distance
            squared_weighted_distances.append(weight * (deviation ** 2))
            total_weight += weight
        
        # Calculate normalized distance
        if total_weight > 0:
            distance = np.sqrt(sum(squared_weighted_distances) / total_weight)
        else:
            distance = float('inf')
        
        return distance, deviations
    
    def _distance_to_similarity(self, distance: float, max_distance: float = 100.0) -> float:
        """
        Convert distance metric to similarity percentage (0-100%).
        
        Args:
            distance: Calculated distance
            max_distance: Maximum expected distance for normalization
            
        Returns:
            Similarity score as percentage
        """
        # Normalize and invert: closer distance = higher similarity
        if distance == float('inf'):
            return 0.0
        
        similarity = max(0.0, 100.0 * (1.0 - min(distance / max_distance, 1.0)))
        return round(similarity, 2)
    
    def analyze_patient(self, patient_data: Dict) -> Dict[str, Any]:
        """
        Analyze patient data against reference database.
        
        This is the main API method for Layer 1. It performs deterministic
        pattern matching and returns structured results for Layer 2 (LLM).
        
        Args:
            patient_data: Patient gait measurement data
            
        Returns:
            Dictionary containing:
                - best_match_id: ID of closest reference
                - similarity_score: Similarity percentage (0-100)
                - deviations: List of significant metric deviations
                - clinical_category: Matched category
                - reference_description: Description of matched reference
                - all_matches: Top 3 matches for context
        """
        if not self.reference_database:
            raise ValueError("Reference database is empty")
        
        best_match = None
        best_distance = float('inf')
        best_deviations = []
        all_matches = []
        
        # Compare against all references
        for reference in self.reference_database:
            distance, deviations = self._calculate_weighted_euclidean_distance(
                patient_data, 
                reference
            )
            
            similarity = self._distance_to_similarity(distance)
            
            all_matches.append({
                'reference_id': reference['reference_id'],
                'similarity_score': similarity,
                'distance': distance,
                'category': reference['clinical_category']
            })
            
            if distance < best_distance:
                best_distance = distance
                best_match = reference
                best_deviations = deviations
        
        # Sort all matches by similarity
        all_matches.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # Format deviations for output (only significant ones)
        significant_deviations = [
            {
                'metric': dev.metric_name.split('.')[-1],
                'full_path': dev.metric_name,
                'patient_value': round(dev.patient_value, 2),
                'reference_value': round(dev.reference_value, 2),
                'deviation': round(dev.deviation, 2),
                'deviation_percentage': round(dev.deviation_percentage, 2),
                'weight': dev.weight,
                'description': f"{dev.metric_name.split('.')[-1]} is {dev.deviation:+.1f} units ({dev.deviation_percentage:+.1f}%) from target"
            }
            for dev in sorted(best_deviations, key=lambda x: abs(x.deviation_percentage), reverse=True)
            if abs(dev.deviation_percentage) > 5.0  # Only show deviations > 5%
        ][:10]  # Top 10 most significant deviations
        
        return {
            'best_match_id': best_match['reference_id'],
            'similarity_score': self._distance_to_similarity(best_distance),
            'clinical_category': best_match['clinical_category'],
            'reference_description': best_match.get('description', ''),
            'clinical_verdict': best_match.get('clinical_verdict', {}),
            'deviations': significant_deviations,
            'all_matches': all_matches[:3],  # Top 3 for context
            'total_references_compared': len(self.reference_database)
        }
    
    